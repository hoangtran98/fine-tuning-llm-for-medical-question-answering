This repository explores the fine-tuning of Large Language Models (LLMs) for the task of answering medical exam questions, using the MedMCQA dataset. While DistilBERT achieved the best accuracy (30.50%), the project highlights the inherent challenges and resource requirements associated with applying LLMs to this specific domain. The findings show that limited performance necessitates further exploration of dataset management techniques and the need for more robust computational resources to enhance the effectiveness of LLMs in the medical field.
